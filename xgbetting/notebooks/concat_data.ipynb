{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = pd.read_csv(\"../data/01.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading 06.csv\n",
      "reading 14.csv\n",
      "reading 17.csv\n",
      "reading 13.csv\n",
      "reading 03.csv\n",
      "reading 11.csv\n",
      "reading 18.csv\n",
      "reading 05.csv\n",
      "reading 10.csv\n",
      "reading 09.csv\n",
      "reading 08.csv\n",
      "reading 19.csv\n",
      "reading 15.csv\n",
      "reading 07.csv\n",
      "reading 04.csv\n",
      "reading 02.csv\n",
      "reading 12.csv\n",
      "reading 16.csv\n"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "for file in os.listdir(\"../data/\"):\n",
    "    if file[0] in ['0', '1'] and file != \"01.csv\":\n",
    "        print(\"reading \" + file)\n",
    "        temp = pd.read_csv(\"../data/\" + file, \n",
    "                                   usecols=list(range(48)), \n",
    "                                   encoding=\"latin-1\")\n",
    "        prev_season = str(int(file[0:2]) - 1)\n",
    "        if len(prev_season) == 1:\n",
    "            prev_season = '0' + prev_season\n",
    "        \n",
    "        temp.loc[:, \"season\"] = prev_season + file[0:2]\n",
    "        df_list.append(temp)\n",
    "df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6521"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True, subset=[\"HomeTeam\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6520"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/pl_to_20180924.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/pl_to_20180924.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ABP', 'AC', 'AF', 'AHW', 'AO', 'AR', 'AS', 'AST', 'AY', 'Attendance',\n",
       "       'AwayTeam', 'B365<2.5', 'B365>2.5', 'B365A', 'B365D', 'B365H', 'BWA',\n",
       "       'BWD', 'BWH', 'Bb1X2', 'BbAvH', 'BbMxD', 'BbMxH', 'Date', 'Div', 'FTAG',\n",
       "       'FTHG', 'FTR', 'GB<2.5', 'GB>2.5', 'GBA', 'GBD', 'GBH', 'HBP', 'HC',\n",
       "       'HF', 'HHW', 'HO', 'HR', 'HS', 'HST', 'HTAG', 'HTHG', 'HTR', 'HY',\n",
       "       'HomeTeam', 'IWA', 'IWD', 'IWH', 'LBA', 'LBD', 'LBH', 'PSA', 'PSD',\n",
       "       'PSH', 'Referee', 'SBA', 'SBD', 'SBH', 'SJA', 'SJD', 'SJH', 'SOA',\n",
       "       'SOD', 'SOH', 'SYA', 'SYD', 'SYH', 'VCA', 'VCD', 'VCH', 'WHA', 'WHD',\n",
       "       'WHH'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check columns of interest are not null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For column Date there are 0 nulls\n",
      "For column HomeTeam there are 0 nulls\n",
      "For column AwayTeam there are 0 nulls\n",
      "For column FTHG there are 0 nulls\n",
      "For column FTAG there are 0 nulls\n",
      "For column FTR there are 0 nulls\n",
      "For column HS there are 0 nulls\n",
      "For column AS there are 0 nulls\n",
      "For column HST there are 0 nulls\n",
      "For column AST there are 0 nulls\n",
      "For column BbMxD there are 5320 nulls\n",
      "For column BbMxH there are 5320 nulls\n"
     ]
    }
   ],
   "source": [
    "for column in ['Date', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', \n",
    "               'FTR', 'HS', 'AS', 'HST', 'AST', 'BbMxD', 'BbMxH']:\n",
    "    nulls = len(df[df[column].isnull()])\n",
    "    print(\"For column {} there are {} nulls\".format(column, nulls))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bet brain Max Draw and Home have lots of missing data. Bet brain Max away doesn't seem to exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate through all files to check where we are missing data for these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading 10.csv\n",
      "Is BbMxD in? True\n",
      "Is BbMxA in? True\n",
      "Is BbMxH in? True\n",
      "reading 11.csv\n",
      "Is BbMxD in? True\n",
      "Is BbMxA in? True\n",
      "Is BbMxH in? True\n",
      "reading 12.csv\n",
      "Is BbMxD in? True\n",
      "Is BbMxA in? True\n",
      "Is BbMxH in? True\n",
      "reading 13.csv\n",
      "Is BbMxD in? True\n",
      "Is BbMxA in? True\n",
      "Is BbMxH in? True\n",
      "reading 14.csv\n",
      "Is BbMxD in? True\n",
      "Is BbMxA in? True\n",
      "Is BbMxH in? True\n",
      "reading 15.csv\n",
      "Is BbMxD in? True\n",
      "Is BbMxA in? True\n",
      "Is BbMxH in? True\n",
      "reading 16.csv\n",
      "Is BbMxD in? True\n",
      "Is BbMxA in? True\n",
      "Is BbMxH in? True\n",
      "reading 17.csv\n",
      "Is BbMxD in? True\n",
      "Is BbMxA in? True\n",
      "Is BbMxH in? True\n",
      "reading 18.csv\n",
      "Is BbMxD in? True\n",
      "Is BbMxA in? True\n",
      "Is BbMxH in? True\n",
      "reading 19.csv\n",
      "Is BbMxD in? True\n",
      "Is BbMxA in? True\n",
      "Is BbMxH in? True\n"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "for file in sorted(os.listdir(\"../data/\")):\n",
    "    if file[0] in ['1'] and file != \"01.csv\":\n",
    "        print(\"reading \" + file)\n",
    "        df = pd.read_csv(\"../data/\" + file, encoding=\"latin-1\")\n",
    "        print(\"Is BbMxD in? {}\".format('BbMxD' in df.columns))\n",
    "        print(\"Is BbMxA in? {}\".format('BbMxA' in df.columns))\n",
    "        print(\"Is BbMxH in? {}\".format('BbMxH' in df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so let's first of all restrict ourselves to making a model just on the goals data, and then worry about betting afterwards, since we have all of the betting data here for the four years to test on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check team names are consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/pl_to_20180924.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Arsenal',\n",
       " 'Aston Villa',\n",
       " 'Birmingham',\n",
       " 'Blackburn',\n",
       " 'Blackpool',\n",
       " 'Bolton',\n",
       " 'Bournemouth',\n",
       " 'Brighton',\n",
       " 'Burnley',\n",
       " 'Cardiff',\n",
       " 'Charlton',\n",
       " 'Chelsea',\n",
       " 'Crystal Palace',\n",
       " 'Derby',\n",
       " 'Everton',\n",
       " 'Fulham',\n",
       " 'Huddersfield',\n",
       " 'Hull',\n",
       " 'Ipswich',\n",
       " 'Leeds',\n",
       " 'Leicester',\n",
       " 'Liverpool',\n",
       " 'Man City',\n",
       " 'Man United',\n",
       " 'Middlesboro',\n",
       " 'Middlesbrough',\n",
       " 'Newcastle',\n",
       " 'Norwich',\n",
       " 'Portsmouth',\n",
       " 'QPR',\n",
       " 'Reading',\n",
       " 'Sheffield United',\n",
       " 'Southampton',\n",
       " 'Stoke',\n",
       " 'Sunderland',\n",
       " 'Swansea',\n",
       " 'Tottenham',\n",
       " 'Watford',\n",
       " 'West Brom',\n",
       " 'West Ham',\n",
       " 'Wigan',\n",
       " 'Wolves']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(df.HomeTeam.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Arsenal',\n",
       " 'Aston Villa',\n",
       " 'Birmingham',\n",
       " 'Blackburn',\n",
       " 'Blackpool',\n",
       " 'Bolton',\n",
       " 'Bournemouth',\n",
       " 'Brighton',\n",
       " 'Burnley',\n",
       " 'Cardiff',\n",
       " 'Charlton',\n",
       " 'Chelsea',\n",
       " 'Crystal Palace',\n",
       " 'Derby',\n",
       " 'Everton',\n",
       " 'Fulham',\n",
       " 'Huddersfield',\n",
       " 'Hull',\n",
       " 'Ipswich',\n",
       " 'Leeds',\n",
       " 'Leicester',\n",
       " 'Liverpool',\n",
       " 'Man City',\n",
       " 'Man United',\n",
       " 'Middlesboro',\n",
       " 'Middlesbrough',\n",
       " 'Newcastle',\n",
       " 'Norwich',\n",
       " 'Portsmouth',\n",
       " 'QPR',\n",
       " 'Reading',\n",
       " 'Sheffield United',\n",
       " 'Southampton',\n",
       " 'Stoke',\n",
       " 'Sunderland',\n",
       " 'Swansea',\n",
       " 'Tottenham',\n",
       " 'Watford',\n",
       " 'West Brom',\n",
       " 'West Ham',\n",
       " 'Wigan',\n",
       " 'Wolves']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(df.AwayTeam.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No one seems to be repeated with different spellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.HomeTeam.unique()) == len(df.AwayTeam.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.setdiff1d(df.HomeTeam.unique(), df.AwayTeam.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.setdiff1d(df.AwayTeam.unique(), df.HomeTeam.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data appears clean for all intents and purposes for building a model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
