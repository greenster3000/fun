{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = pd.read_csv(\"../data/01.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading 06.csv\n",
      "reading 14.csv\n",
      "reading 17.csv\n",
      "reading 13.csv\n",
      "reading 03.csv\n",
      "reading 11.csv\n",
      "reading 18.csv\n",
      "reading 05.csv\n",
      "reading 10.csv\n",
      "reading 09.csv\n",
      "reading 08.csv\n",
      "reading 19.csv\n",
      "reading 15.csv\n",
      "reading 07.csv\n",
      "reading 04.csv\n",
      "reading 02.csv\n",
      "reading 12.csv\n",
      "reading 16.csv\n"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "for file in os.listdir(\"../data/\"):\n",
    "    if file[0] in ['0', '1'] and file != \"01.csv\":\n",
    "        print(\"reading \" + file)\n",
    "        temp = pd.read_csv(\"../data/\" + file, \n",
    "                                   usecols=list(range(48)), \n",
    "                                   encoding=\"latin-1\")\n",
    "        prev_season = str(int(file[0:2]) - 1)\n",
    "        if len(prev_season) == 1:\n",
    "            prev_season = '0' + prev_season\n",
    "        \n",
    "        temp.loc[:, \"season\"] = prev_season + file[0:2]\n",
    "        df_list.append(temp)\n",
    "df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6521"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True, subset=[\"HomeTeam\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6520"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/pl_to_20180924.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/pl_to_20180924.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ABP', 'AC', 'AF', 'AHW', 'AO', 'AR', 'AS', 'AST', 'AY', 'Attendance',\n",
       "       'AwayTeam', 'B365<2.5', 'B365>2.5', 'B365A', 'B365D', 'B365H', 'BWA',\n",
       "       'BWD', 'BWH', 'Bb1X2', 'BbAvH', 'BbMxD', 'BbMxH', 'Date', 'Div', 'FTAG',\n",
       "       'FTHG', 'FTR', 'GB<2.5', 'GB>2.5', 'GBA', 'GBD', 'GBH', 'HBP', 'HC',\n",
       "       'HF', 'HHW', 'HO', 'HR', 'HS', 'HST', 'HTAG', 'HTHG', 'HTR', 'HY',\n",
       "       'HomeTeam', 'IWA', 'IWD', 'IWH', 'LBA', 'LBD', 'LBH', 'PSA', 'PSD',\n",
       "       'PSH', 'Referee', 'SBA', 'SBD', 'SBH', 'SJA', 'SJD', 'SJH', 'SOA',\n",
       "       'SOD', 'SOH', 'SYA', 'SYD', 'SYH', 'VCA', 'VCD', 'VCH', 'WHA', 'WHD',\n",
       "       'WHH'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check columns of interest are not null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For column Date there are 0 nulls\n",
      "For column HomeTeam there are 0 nulls\n",
      "For column AwayTeam there are 0 nulls\n",
      "For column FTHG there are 0 nulls\n",
      "For column FTAG there are 0 nulls\n",
      "For column FTR there are 0 nulls\n",
      "For column HS there are 0 nulls\n",
      "For column AS there are 0 nulls\n",
      "For column HST there are 0 nulls\n",
      "For column AST there are 0 nulls\n",
      "For column BbMxD there are 5320 nulls\n",
      "For column BbMxH there are 5320 nulls\n"
     ]
    }
   ],
   "source": [
    "for column in ['Date', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', \n",
    "               'FTR', 'HS', 'AS', 'HST', 'AST', 'BbMxD', 'BbMxH']:\n",
    "    nulls = len(df[df[column].isnull()])\n",
    "    print(\"For column {} there are {} nulls\".format(column, nulls))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bet brain Max Draw and Home have lots of missing data. Bet brain Max away doesn't seem to exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate through all files to check where we are missing data for these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading 10.csv\n",
      "Is BbMxD in? True\n",
      "Is BbMxA in? True\n",
      "Is BbMxH in? True\n",
      "reading 11.csv\n",
      "Is BbMxD in? True\n",
      "Is BbMxA in? True\n",
      "Is BbMxH in? True\n",
      "reading 12.csv\n",
      "Is BbMxD in? True\n",
      "Is BbMxA in? True\n",
      "Is BbMxH in? True\n",
      "reading 13.csv\n",
      "Is BbMxD in? True\n",
      "Is BbMxA in? True\n",
      "Is BbMxH in? True\n",
      "reading 14.csv\n",
      "Is BbMxD in? True\n",
      "Is BbMxA in? True\n",
      "Is BbMxH in? True\n",
      "reading 15.csv\n",
      "Is BbMxD in? True\n",
      "Is BbMxA in? True\n",
      "Is BbMxH in? True\n",
      "reading 16.csv\n",
      "Is BbMxD in? True\n",
      "Is BbMxA in? True\n",
      "Is BbMxH in? True\n",
      "reading 17.csv\n",
      "Is BbMxD in? True\n",
      "Is BbMxA in? True\n",
      "Is BbMxH in? True\n",
      "reading 18.csv\n",
      "Is BbMxD in? True\n",
      "Is BbMxA in? True\n",
      "Is BbMxH in? True\n",
      "reading 19.csv\n",
      "Is BbMxD in? True\n",
      "Is BbMxA in? True\n",
      "Is BbMxH in? True\n"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "for file in sorted(os.listdir(\"../data/\")):\n",
    "    if file[0] in ['1'] and file != \"01.csv\":\n",
    "        print(\"reading \" + file)\n",
    "        df = pd.read_csv(\"../data/\" + file, encoding=\"latin-1\")\n",
    "        print(\"Is BbMxD in? {}\".format('BbMxD' in df.columns))\n",
    "        print(\"Is BbMxA in? {}\".format('BbMxA' in df.columns))\n",
    "        print(\"Is BbMxH in? {}\".format('BbMxH' in df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so let's first of all restrict ourselves to making a model just on the goals data, and then worry about betting afterwards, since we have all of the betting data here for the four years to test on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check team names are consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/pl_to_20180924.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Arsenal',\n",
       " 'Aston Villa',\n",
       " 'Birmingham',\n",
       " 'Blackburn',\n",
       " 'Blackpool',\n",
       " 'Bolton',\n",
       " 'Bournemouth',\n",
       " 'Brighton',\n",
       " 'Burnley',\n",
       " 'Cardiff',\n",
       " 'Charlton',\n",
       " 'Chelsea',\n",
       " 'Crystal Palace',\n",
       " 'Derby',\n",
       " 'Everton',\n",
       " 'Fulham',\n",
       " 'Huddersfield',\n",
       " 'Hull',\n",
       " 'Ipswich',\n",
       " 'Leeds',\n",
       " 'Leicester',\n",
       " 'Liverpool',\n",
       " 'Man City',\n",
       " 'Man United',\n",
       " 'Middlesboro',\n",
       " 'Middlesbrough',\n",
       " 'Newcastle',\n",
       " 'Norwich',\n",
       " 'Portsmouth',\n",
       " 'QPR',\n",
       " 'Reading',\n",
       " 'Sheffield United',\n",
       " 'Southampton',\n",
       " 'Stoke',\n",
       " 'Sunderland',\n",
       " 'Swansea',\n",
       " 'Tottenham',\n",
       " 'Watford',\n",
       " 'West Brom',\n",
       " 'West Ham',\n",
       " 'Wigan',\n",
       " 'Wolves']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(df.HomeTeam.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Arsenal',\n",
       " 'Aston Villa',\n",
       " 'Birmingham',\n",
       " 'Blackburn',\n",
       " 'Blackpool',\n",
       " 'Bolton',\n",
       " 'Bournemouth',\n",
       " 'Brighton',\n",
       " 'Burnley',\n",
       " 'Cardiff',\n",
       " 'Charlton',\n",
       " 'Chelsea',\n",
       " 'Crystal Palace',\n",
       " 'Derby',\n",
       " 'Everton',\n",
       " 'Fulham',\n",
       " 'Huddersfield',\n",
       " 'Hull',\n",
       " 'Ipswich',\n",
       " 'Leeds',\n",
       " 'Leicester',\n",
       " 'Liverpool',\n",
       " 'Man City',\n",
       " 'Man United',\n",
       " 'Middlesboro',\n",
       " 'Middlesbrough',\n",
       " 'Newcastle',\n",
       " 'Norwich',\n",
       " 'Portsmouth',\n",
       " 'QPR',\n",
       " 'Reading',\n",
       " 'Sheffield United',\n",
       " 'Southampton',\n",
       " 'Stoke',\n",
       " 'Sunderland',\n",
       " 'Swansea',\n",
       " 'Tottenham',\n",
       " 'Watford',\n",
       " 'West Brom',\n",
       " 'West Ham',\n",
       " 'Wigan',\n",
       " 'Wolves']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(df.AwayTeam.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No one seems to be repeated with different spellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.HomeTeam.unique()) == len(df.AwayTeam.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.setdiff1d(df.HomeTeam.unique(), df.AwayTeam.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.setdiff1d(df.AwayTeam.unique(), df.HomeTeam.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data appears clean for all intents and purposes for building a model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01.csv\n",
      "02.csv\n",
      "03.csv\n",
      "04.csv\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 57 fields in line 305, saw 72\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8144c2b03c17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"latin-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#     if file[0] in ['1'] and file != \"01.csv\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#         print(\"reading \" + file)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alexander/anaconda/envs/py36/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alexander/anaconda/envs/py36/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alexander/anaconda/envs/py36/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1003\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skipfooter not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1005\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'as_recarray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alexander/anaconda/envs/py36/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1746\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1747\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1748\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1749\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read (pandas/_libs/parsers.c:10862)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory (pandas/_libs/parsers.c:11138)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows (pandas/_libs/parsers.c:11884)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows (pandas/_libs/parsers.c:11755)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error (pandas/_libs/parsers.c:28765)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 57 fields in line 305, saw 72\n"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "for file in sorted(os.listdir(\"../data/\")):\n",
    "    print(file)\n",
    "    file = pd.read_csv(\"../data/\" + file, encoding=\"latin-1\"03)\n",
    "#     if file[0] in ['1'] and file != \"01.csv\":\n",
    "#         print(\"reading \" + file)\n",
    "#         df = pd.read_csv(\"../data/\" + file, encoding=\"latin-1\")\n",
    "#         print(\"Is BbMxD in? {}\".format('BbMxD' in df.columns))\n",
    "#         print(\"Is BbMxA in? {}\".format('BbMxA' in df.columns))\n",
    "#         print(\"Is BbMxH in? {}\".format('BbMxH' in df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
